import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from xgboost import XGBClassifier, XGBRegressor
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np
import matplotlib.pyplot as plt
import io
from fpdf import FPDF

st.title("ü§ñ AutoML Universal")

# Upload
df_file = st.file_uploader("Carregue seu arquivo (CSV, Excel, SQLite, Feather)", 
                           type=["csv","xlsx","xls","db","sqlite","ftr"])

if df_file is not None:
    # Detectar formato
    if str(df_file.name).endswith(".csv"):
        df = pd.read_csv(df_file)
    elif str(df_file.name).endswith((".xlsx",".xls")):
        df = pd.read_excel(df_file)
    elif str(df_file.name).endswith((".db",".sqlite")):
        import sqlite3
        conn = sqlite3.connect(df_file.name)
        df = pd.read_sql("SELECT * FROM tabela", conn)  # ajuste conforme sua tabela
    elif str(df_file.name).endswith(".ftr"):
        df = pd.read_feather(df_file)

    st.success(f"‚úÖ Arquivo carregado com {df.shape[0]} linhas e {df.shape[1]} colunas")

    # ================================
    # Sidebar
    # ================================
    st.sidebar.header("‚öôÔ∏è Configura√ß√µes")

    alvo = st.sidebar.selectbox("üéØ Selecione a coluna alvo", df.columns)

    # Slider para quantidade de linhas
    num_linhas = st.sidebar.slider(
        "üìä Quantidade de linhas a usar",
        min_value=100,
        max_value=len(df),
        value=min(1000, len(df)),
        step=100
    )

    df_final = df.head(num_linhas)

    st.write(f"üìä Dados selecionados (primeiras {num_linhas} linhas):")
    st.dataframe(df_final)

    # ================================
    # Pr√©-processamento
    # ================================
    y = df_final[alvo]
    X = df_final.drop(columns=[alvo])

    if "data_ref" in X.columns:
        X["data_ref"] = pd.to_datetime(X["data_ref"], errors="coerce").astype(int) // 10**9

    X = pd.get_dummies(X, drop_first=True).fillna(0)
    X = X.apply(pd.to_numeric, errors="coerce").fillna(0)

    # Detectar problema
    if pd.api.types.is_numeric_dtype(y) and y.nunique() > 15:
        problema = "regressao"
        y = pd.to_numeric(y, errors="coerce").fillna(y.mean())
    else:
        problema = "classificacao"
        y = y.astype("category").cat.codes

    st.info(f"üîé Detectado problema de **{problema.upper()}**")

    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Modelos
    if problema == "classificacao":
        modelos = {
            "Logistic Regression": LogisticRegression(max_iter=1000),
            "Random Forest Classifier": RandomForestClassifier(),
            "XGBClassifier": XGBClassifier(use_label_encoder=False, eval_metric="mlogloss")
        }
    else:
        modelos = {
            "Linear Regression": LinearRegression(),
            "Random Forest Regressor": RandomForestRegressor(),
            "XGBRegressor": XGBRegressor()
        }

    resultados = {}
    variaveis_importancia = {}

    # Treinamento
    for nome, modelo in modelos.items():
        try:
            modelo.fit(X_train, y_train)
            y_pred = modelo.predict(X_test)

            if problema == "classificacao":
                resultados[nome] = {
                    "Acur√°cia": accuracy_score(y_test, y_pred),
                    "F1-Score": f1_score(y_test, y_pred, average="weighted"),
                    "Precis√£o": precision_score(y_test, y_pred, average="weighted"),
                    "Recall": recall_score(y_test, y_pred, average="weighted")
                }
            else:
                resultados[nome] = {
                    "R¬≤": r2_score(y_test, y_pred),
                    "RMSE": np.sqrt(mean_squared_error(y_test, y_pred)),
                    "MAE": mean_absolute_error(y_test, y_pred)
                }

            # Import√¢ncia das vari√°veis
            if hasattr(modelo, "feature_importances_"):
                imp = modelo.feature_importances_
            elif hasattr(modelo, "coef_"):
                coef = modelo.coef_[0] if len(modelo.coef_.shape) > 1 else modelo.coef_
                imp = np.abs(coef)
            else:
                imp = np.zeros(X.shape[1])

            df_imp = pd.DataFrame({"Vari√°vel": X.columns, "Import√¢ncia": imp})
            variaveis_importancia[nome] = df_imp.sort_values("Import√¢ncia", ascending=False)

        except Exception as e:
            resultados[nome] = f"Erro: {e}"

    # ================================
    # Relat√≥rio Final na Tela
    # ================================
    st.subheader("üìë Relat√≥rio Final")
    df_resultados = pd.DataFrame(resultados).T
    st.dataframe(df_resultados.style.highlight_max(axis=0, color="lightgreen"))

    st.subheader("üìå Import√¢ncia das Vari√°veis")
    for modelo, df_imp in variaveis_importancia.items():
        st.markdown(f"**{modelo}**")
        st.dataframe(df_imp.head(10).style.background_gradient(cmap="Blues"))
# ================================
# Aba de Explica√ß√µes e Insights
# ================================
st.subheader("üìñ Explica√ß√µes e Insights")

tab1, tab2 = st.tabs(["Por que este modelo?", "Insights de Neg√≥cio"])

with tab1:
    st.write("### Justificativa da escolha dos modelos")
    if problema == "classificacao":
        st.markdown("""
        - **Logistic Regression**: modelo simples e interpret√°vel, √∫til para entender rela√ß√µes lineares entre vari√°veis.
        - **Random Forest Classifier**: combina v√°rias √°rvores de decis√£o, robusto contra overfitting e captura rela√ß√µes n√£o lineares.
        - **XGBClassifier**: algoritmo de boosting altamente eficiente, √≥timo para dados complexos e competi√ß√µes de machine learning.
        """)
    else:
        st.markdown("""
        - **Linear Regression**: modelo b√°sico e interpret√°vel, bom para rela√ß√µes lineares.
        - **Random Forest Regressor**: captura intera√ß√µes complexas entre vari√°veis e √© robusto contra ru√≠do.
        - **XGBRegressor**: modelo de boosting que otimiza erros residuais, excelente para alta performance em regress√£o.
        """)

with tab2:
    st.write("### Insights de Neg√≥cio")
    if isinstance(df_resultados, pd.DataFrame):
        melhor_modelo = max(
            resultados.items(),
            key=lambda x: x[1][list(x[1].keys())[0]] if isinstance(x[1], dict) else -999
        )[0]
        st.info(f"O modelo que mais se destacou foi **{melhor_modelo}**.")

    st.markdown("""
    - Use o modelo com melhor desempenho para prever novos dados.
    - Analise as vari√°veis mais importantes para orientar decis√µes estrat√©gicas.
    - Modelos complexos como XGBoost ajudam a identificar padr√µes ocultos.
    - Se o objetivo for reduzir erro, priorize o modelo com menor RMSE ou MAE.
    """)
    # ================================
    # Gr√°ficos Comparativos
    # ================================
    st.subheader("üìä Gr√°ficos Comparativos")

    if problema == "classificacao":
        for metrica, cor in zip(["Acur√°cia","F1-Score","Precis√£o","Recall"],
                                ["skyblue","orange","green","purple"]):
            valores = {m: resultados[m][metrica] for m in resultados if isinstance(resultados[m], dict)}
            fig, ax = plt.subplots()
            ax.bar(valores.keys(), valores.values(), color=cor)
            ax.set_title(f"Compara√ß√£o de {metrica}")
            ax.set_ylabel(metrica)
            st.pyplot(fig)
    else:
        for metrica, cor in zip(["R¬≤","RMSE","MAE"],
                                ["skyblue","orange","green"]):
            valores = {m: resultados[m][metrica] for m in resultados if isinstance(resultados[m], dict)}
            fig, ax = plt.subplots()
            ax.bar(valores.keys(), valores.values(), color=cor)
            ax.set_title(f"Compara√ß√£o de {metrica}")
            ax.set_ylabel(metrica)
            st.pyplot(fig)

    # ================================
    # Exporta√ß√£o de Relat√≥rios
    # ================================
    st.subheader("üì• Exportar Relat√≥rios")

    # Bot√£o CSV
    csv = df_resultados.to_csv(index=True).encode("utf-8")
    st.download_button("‚¨áÔ∏è Baixar CSV", csv, "relatorio_modelos.csv", "text/csv")

    # Fun√ß√£o para nomes seguros de abas
    def safe_sheet_name(name: str) -> str:
        return ("Imp_" + name.replace(" ", "_"))[:31]

    # Bot√£o Excel
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        df_resultados.to_excel(writer, sheet_name="Resultados")
        for nome, df_imp in variaveis_importancia.items():
            df_imp.to_excel(writer, sheet_name=safe_sheet_name(nome))
    st.download_button("‚¨áÔ∏è Baixar Excel", buffer.getvalue(),
                       "relatorio_completo.xlsx",
                       "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # Bot√£o PDF
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="Relat√≥rio de Modelos", ln=True, align="C")

    def clean_text(text):
        return text.encode("latin-1", "ignore").decode("latin-1")

    for modelo, metricas in resultados.items():
        if isinstance(metricas, dict):
            for metrica, valor in metricas.items():
                pdf.cell(200, 10, txt=clean_text(f"{modelo} - {metrica}: {valor:.4f}"), ln=True, align="L")
        else:
            pdf.cell(200, 10, txt=clean_text(f"{modelo}: {metricas}"), ln=True, align="L")

    pdf.add_page()
pdf.cell(200, 10, txt="Import√¢ncia das Vari√°veis", ln=True, align="C")

for modelo, df_imp in variaveis_importancia.items():
    pdf.cell(200, 10, txt=clean_text(f"{modelo}"), ln=True, align="L")
    for _, row in df_imp.head(10).iterrows():
        pdf.cell(200, 10, txt=clean_text(f"{row['Vari√°vel']}: {row['Import√¢ncia']:.4f}"), ln=True, align="L")

# Exporta PDF
pdf_output = pdf.output(dest="S").encode("latin-1", "ignore")
st.download_button(
    label="‚¨áÔ∏è Baixar relat√≥rio em PDF",
    data=pdf_output,
    file_name="relatorio_completo.pdf",
    mime="application/pdf"
)